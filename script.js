var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition
var SpeechGrammarList = SpeechGrammarList || webkitSpeechGrammarList
var SpeechRecognitionEvent = SpeechRecognitionEvent || webkitSpeechRecognitionEvent

var colors = [ 'aqua' , 'azure' , 'beige', 'bisque', 'black', 'blue', 'brown', 'chocolate', 'coral', 'crimson', 'cyan', 'fuchsia', 'ghostwhite', 'gold', 'goldenrod', 'gray', 'green', 'indigo', 'ivory', 'khaki', 'lavender', 'lime', 'linen', 'magenta', 'maroon', 'moccasin', 'navy', 'olive', 'orange', 'orchid', 'peru', 'pink', 'plum', 'purple', 'red', 'salmon', 'sienna', 'silver', 'snow', 'tan', 'teal', 'thistle', 'tomato', 'turquoise', 'violet', 'white', 'yellow'];
var grammar = '#JSGF V1.0; grammar colors; public <color> = ' + colors.join(' | ') + ' ;'

var recognition = new SpeechRecognition();
var speechRecognitionList = new SpeechGrammarList();
speechRecognitionList.addFromString(grammar, 3);
recognition.grammars = speechRecognitionList;
recognition.continuous = false;
recognition.lang = 'ru';
recognition.interimResults = false;
recognition.maxAlternatives = 3;

var diagnostic = document.querySelector('.output');
var qqq = document.querySelector('.qqq');
var bg = document.querySelector('html');
var hints = document.querySelector('.hints');

var colorHTML= '';
colors.forEach(function(v, i, a){
  console.log(v, i);
  // colorHTML += '<span style="background-color:' + v + ';"> ' + v + ' </span>';
});
hints.innerHTML = '–ö–ª–∏–∫–Ω–∏—Ç–µ –º—ã—à–∫–æ–π üêÅ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.';

document.body.onclick = function() {
  recognition.start();
  console.log('Ready to receive a color command.');
}

recognition.onresult = function(event) {
  // The SpeechRecognitionEvent results property returns a SpeechRecognitionResultList object
  // The SpeechRecognitionResultList object contains SpeechRecognitionResult objects.
  // It has a getter so it can be accessed like an array
  // The first [0] returns the SpeechRecognitionResult at the last position.
  // Each SpeechRecognitionResult object contains SpeechRecognitionAlternative objects that contain individual results.
  // These also have getters so they can be accessed like arrays.
  // The second [0] returns the SpeechRecognitionAlternative at position 0.
  // We then return the transcript property of the SpeechRecognitionAlternative object
  var color = event.results[0][0].transcript;
  diagnostic.textContent = '–í—ã —Å–∫–∞–∑–∞–ª–∏: ' + color + '. ';
  if (color == '—Å–∏—Å—Ç–µ–º–∞ –¥–∏—Å—Ç–∞–Ω—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è') {
    bg.style.backgroundColor = 'green';
    qqq.textContent = '–í—Å–µ –≤–µ—Ä–Ω–æ';
    newpage();
  }
//—Å–∏—Å—Ç–µ–º–∞ –¥–∏—Å—Ç–∞–Ω—Ü–∏–æ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
  console.log('Confidence: ' + event.results[0][0].confidence);
}

recognition.onspeechend = function() {
  recognition.stop();
}

recognition.onnomatch = function(event) {
  diagnostic.textContent = "–ù–µ –º–æ–≥—É —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≤–∞—à—É —Ñ—Ä–∞–∑—É";
}

recognition.onerror = function(event) {
  diagnostic.textContent = '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–æ–≤–∞–Ω–∏—è: ' + event.error;
}


function newpage() {
  setTimeout(function(){
    window.location.href = 'index1.html';
  }, 5 * 1000);
}
